{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca916d2",
   "metadata": {
    "id": "3RE7NULIPhwW"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3f7ccd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yQhHXw96P8ed",
    "outputId": "2056d186-a766-4d3f-b0be-3da3cc7b989a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 14:26:50 2009</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 14 10:13:55 2009</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 05 21:02:20 2009</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 14 22:25:52 2009</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 00:42:12 2009</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "0      0  Fri Jun 05 14:26:50 2009   \n",
       "1      1  Thu May 14 10:13:55 2009   \n",
       "2      1  Fri Jun 05 21:02:20 2009   \n",
       "3      1  Sun Jun 14 22:25:52 2009   \n",
       "4      1  Sun May 31 00:42:12 2009   \n",
       "\n",
       "                                                TEXT  \n",
       "0                  About to get threaded and scared   \n",
       "1  @awaisnaseer I like Shezan Mangooo too!!! I ha...  \n",
       "2  worked on my car after work. showering then go...  \n",
       "3  @Marama Actually we start this afternoon!  I w...  \n",
       "4  @gfalcone601 Aww Gi.don't worry.we'll vote for...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset\n",
    "\n",
    "raw_data = pd.read_csv(\"A2_data.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f785268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7ekqdIyQcsF",
    "outputId": "048bf2b9-7273-467a-e355-d39bfb160098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2287\n",
       "0    2000\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check count of each labels in dataset\n",
    "raw_data.LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae7cb02",
   "metadata": {},
   "source": [
    "### The data is a bit skewed towards the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cbe8f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22535e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from autocorrect import Speller\n",
    "\n",
    "\n",
    "# create object for lemmetizer and spelling checking\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    # create required columns and initialize with 0\n",
    "    \n",
    "    df['white_space_removed'] = 0\n",
    "    df['tokenized_data'] = 0\n",
    "    df['stopword_removed_data'] = 0\n",
    "    df['punct_removed_data'] = 0\n",
    "    df['url_removed_data'] = 0\n",
    "    df['spelling_checked_data'] = 0\n",
    "    df['lemmetized_data'] = 0\n",
    "    df['preprocessed_txt'] = 0\n",
    "    \n",
    "    # iterate over each row of dataset and preprocess data\n",
    "    sentences\n",
    "    for i in range(df.shape[0]):\n",
    "\n",
    "        # white space removel\n",
    "        \n",
    "        df['white_space_removed'][i] = re.sub(\"\\s+\", \" \", df.TEXT[i])\n",
    "\n",
    "\n",
    "        # tokenization\n",
    "        \n",
    "        lower = df['white_space_removed'][i].lower()\n",
    "        tokenized_data = word_tokenize(lower)\n",
    "        df['tokenized_data'][i] = tokenized_data\n",
    "        \n",
    "        \n",
    "\n",
    "        # remove stopwords\n",
    "        \n",
    "        stop_words = \"|\".join(stopwords.words('english'))\n",
    "        pattern = re.compile(r'\\b(' + stop_words + r')\\b\\s*')\n",
    "        stopword_removed_data = [pattern.sub(\"\", text) for text in tokenized_data]\n",
    "        stopword_removed_data = [x for x in stopword_removed_data if x]\n",
    "        \n",
    "        df['stopword_removed_data'][i] = stopword_removed_data         \n",
    "       \n",
    "\n",
    "        # punctuation removel\n",
    "        \n",
    "        punct_removed_data = [x for x in stopword_removed_data if x.isalnum()]\n",
    "        df['punct_removed_data'][i] = punct_removed_data\n",
    "\n",
    "\n",
    "\n",
    "        # remove urls and html tags\n",
    "        \n",
    "        urls = re.findall(\"https?://[a-zA-Z0-9_\\?=\\@\\/#=.~-]+\", \" \".join(punct_removed_data))\n",
    "        url_removed_data = [x for x in punct_removed_data if x not in urls]\n",
    "        df['url_removed_data'][i] = url_removed_data\n",
    " \n",
    "\n",
    "\n",
    "        # spelling checking\n",
    "    \n",
    "        spelling_checked_data = [spell(x) for x in url_removed_data]\n",
    "        df['spelling_checked_data'][i] = spelling_checked_data\n",
    "\n",
    "\n",
    "        # lemmetization\n",
    "        \n",
    "        lemmas = []\n",
    "        for w in spelling_checked_data:\n",
    "            lemmas.append(lemmatizer.lemmatize(w, wordnet.VERB))\n",
    "            df['lemmetized_data'][i] = lemmas\n",
    "        \n",
    "        if(str(df['lemmetized_data'][i]) == '0'):\n",
    "            df.drop(i)\n",
    "        else:\n",
    "            df['preprocessed_txt'][i] = \" \".join(df['lemmetized_data'][i])\n",
    "            \n",
    "        x = df['preprocessed_txt'][i]\n",
    "        if(type(x)!='str'):\n",
    "            x=str(x)\n",
    "        x = '<s> ' + x + ' </s>'\n",
    "        df['preprocessed_txt'][i]=x    \n",
    "        \n",
    "    print(\"PREPROCESSING PIPELINE AT A GLANCE\")    \n",
    "    display(df.head())\n",
    "    df = df[['LABEL','DATE_TIME','preprocessed_txt']]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce0ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_copy_processed = preprocess(raw_data.copy())\n",
    "print(\"PREPROCESSED DATA\")\n",
    "display(raw_data_copy_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_copy_processed.to_csv('A2_dataset_processed.csv',encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23178a1c",
   "metadata": {},
   "source": [
    "## Q1- laplace smoothing  transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8724cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocabulary : 7349\n"
     ]
    }
   ],
   "source": [
    "# read preprocessed data\n",
    "processed_data = pd.read_csv('A2_dataset_processed.csv')\n",
    "\n",
    "\n",
    "#count unigram frequencies and prepare vocabulary set\n",
    "vocab = set()\n",
    "unigram_count = {}\n",
    "    \n",
    "\n",
    "for x in processed_data['preprocessed_txt'].to_list():    \n",
    "    for y in x.split():\n",
    "        vocab.add(y)\n",
    "        if y in unigram_count:\n",
    "            unigram_count[y] += 1\n",
    "        else:\n",
    "            unigram_count[y] = 1\n",
    "\n",
    "vocab = list(vocab)\n",
    "print(\"length of vocabulary :\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e55186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'get'),\n",
       " ('get', 'thread'),\n",
       " ('thread', 'scar'),\n",
       " ('scar', '</s>'),\n",
       " ('<s>', 'awaisnaseer')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count bigram frequencies of only existing bigrams; rest are trivially 0\n",
    "bigram_count={}      \n",
    "            \n",
    "            \n",
    "for line in processed_data.preprocessed_txt.to_list():\n",
    "            list_words = line.split()\n",
    "            for k in range(len(list_words)-1):\n",
    "                i = list_words[k]\n",
    "                j = list_words[k+1]\n",
    "                if(i,j) in bigram_count:\n",
    "                    bigram_count[(i,j)] += 1\n",
    "                else:\n",
    "                    bigram_count[(i,j)] = 1                \n",
    "                \n",
    "list(bigram_count)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate updated bigram probability using laplace transform over entire dataset and print top 4 \n",
    "v = vocab\n",
    "vocab_size = len(vocab)\n",
    "lap_bigram_probs = {}\n",
    "\n",
    "for i in v:\n",
    "    for j in v:\n",
    "        if(i,j) in bigram_count:\n",
    "            lap_bigram_probs[(i,j)] = (bigram_count[(i,j)] + 1)/(unigram_count[i] + vocab_size) \n",
    "        else:\n",
    "            lap_bigram_probs[(i,j)] = 1/(unigram_count[i] + vocab_size)\n",
    "            \n",
    "with open('lap_bigram_probs.pickle', 'wb') as handle:\n",
    "    pickle.dump(lap_bigram_probs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "del lap_bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dce61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read laplace probability of bigram from pickle \n",
    "with open('lap_bigram_probs.pickle', 'rb') as handle:\n",
    "    lap_bigram_probs = pickle.load(handle)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd61b5",
   "metadata": {},
   "source": [
    "# print top 4 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16306240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 4 bigrams\n",
      "(('http', '</s>'), 0.014073287307488051)\n",
      "(('lol', '</s>'), 0.008906021533962515)\n",
      "(('gon', 'na'), 0.00823322985558105)\n",
      "(('day', '</s>'), 0.006479767257339328)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"top 4 bigrams\")\n",
    "for (k, v) in Counter(lap_bigram_probs).most_common(4):            \n",
    "    print((k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a75d6",
   "metadata": {},
   "source": [
    "## Next word generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5495c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate most probable next word after 'context'\n",
    "def next_word(context):   \n",
    "    r = random.random()\n",
    "    map_to_probs = {}\n",
    "    \n",
    "    # prob. of occurrence of each word 'token' after 'context'\n",
    "    for token in vocab:\n",
    "        map_to_probs[token] = lap_bigram_probs[(context, token)]    \n",
    "    \n",
    "    # summ stores cumulative probabilities of occurrence of a word after a 'context' \n",
    "    summ = 0  \n",
    "    for token in (map_to_probs):\n",
    "        summ += map_to_probs[token] \n",
    "        if (summ > r):\n",
    "            return token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c374c96",
   "metadata": {},
   "source": [
    "## Sentance generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d487b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> tashadhanraj lathe teddy underwood wake mat dun confessing7girl julibarcelona cigarettes johngreenaway drunken uch jonbecker infinity corner satisfy store presentations wise </s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sentences\n",
    "def generate_text(): \n",
    "        minn = 7\n",
    "        maxx = 20\n",
    "        context_queue = '<s>' #current last word seen/generated; sent as 'context' to next_word() function\n",
    "        result = ['<s>']  #entire sentence generated upto present time \n",
    "        \n",
    "        c = 1\n",
    "        while  c <= maxx :\n",
    "            obj = next_word(context_queue)\n",
    "            if obj == '</s>' and c <= minn:\n",
    "                continue\n",
    "            elif obj == '</s>' and c > minn:\n",
    "                break\n",
    "            else: \n",
    "                context_queue = obj\n",
    "                result.append(obj)\n",
    "                c += 1\n",
    "                            \n",
    "        result.append('</s>')\n",
    "        return ' '.join(result)\n",
    "    \n",
    "generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1df43a",
   "metadata": {},
   "source": [
    "## genrate 500 sentences using smoothed probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2556b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> good severe marleematlin kreesha mind night nj deeper toast list geog yasmimmm cameronreilly excitement backlog lord 3rd 1week suck harper </s>\n",
      "<s> chopsuey2e zhang political fabuleuxdestin afterwards bad jeremy poke sowwiiiee tilde chick r2e2 yan dif super nareejo semuuaa afternoon pc uugggh </s>\n",
      "<s> mosquito 4am lobster top vernongarrett calgary greatfitness knowwwwww mc insure shogi 5th benny doingwork l8ly popularity normally ncaa tweak costa </s>\n",
      "<s> okay dunkndisorderly tutor mommapuff souvenir sketchbook mwahahaha financial goodnight jenny hoopinispassion howliet sudden kea34 sri join60seconds offline shaft secular matthewsheppard </s>\n",
      "<s> lucypope hoaaaaaaaaaaaaa caffeine mark liturgy wheel ceiling toronto dow werewolfseth m0t0breath h0area getknifed yourproxycomm product 45 affairs solar funky tent </s>\n"
     ]
    }
   ],
   "source": [
    "sentences_500_no_beta = []\n",
    "for i in range(500):\n",
    "    sentences_500_no_beta.append(generate_text())\n",
    "\n",
    "#  print first 5 generated sentences\n",
    "for s in sentences_500_no_beta[:5]:\n",
    "    print(s)\n",
    "    \n",
    "del lap_bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c9dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "scores = []\n",
    "mod_scores = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "def sentiment_scores(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    scores.append(sentiment_dict['compound'])\n",
    "    mod_scores.append(abs(sentiment_dict['compound']))\n",
    "    \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] > 0 :\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "        \n",
    "for s in sentences_500_no_beta:\n",
    "    sentiment_scores(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9ad3b",
   "metadata": {},
   "source": [
    "## Save generated sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b02cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5895ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; good severe marleematlin kreesha mind nigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; chopsuey2e zhang political fabuleuxdestin ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; mosquito 4am lobster top vernongarrett cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; okay dunkndisorderly tutor mommapuff souve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; lucypope hoaaaaaaaaaaaaa caffeine mark lit...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  labels  vader_scores  \\\n",
       "0  <s> good severe marleematlin kreesha mind nigh...       1        0.1531   \n",
       "1  <s> chopsuey2e zhang political fabuleuxdestin ...       1        0.1027   \n",
       "2  <s> mosquito 4am lobster top vernongarrett cal...       1        0.5994   \n",
       "3  <s> okay dunkndisorderly tutor mommapuff souve...       1        0.1027   \n",
       "4  <s> lucypope hoaaaaaaaaaaaaa caffeine mark lit...       0       -0.1027   \n",
       "\n",
       "   mod_vader_scores  \n",
       "0            0.1531  \n",
       "1            0.1027  \n",
       "2            0.5994  \n",
       "3            0.1027  \n",
       "4            0.1027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_no_beta = pd.DataFrame({'sentences': sentences_500_no_beta, 'labels': labels, 'vader_scores': scores, 'mod_vader_scores': mod_scores})\n",
    "display(df_no_beta.head(5))\n",
    "df_no_beta.to_csv('df_no_beta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0561892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vader score without beta :  0.3616596\n"
     ]
    }
   ],
   "source": [
    "avg_vader_score_no_beta = sum(mod_scores) / len(mod_scores)\n",
    "print(\"average vader score without beta : \", avg_vader_score_no_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480b4f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_no_beta.loc[df_no_beta.labels == 1]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3c73a",
   "metadata": {},
   "source": [
    "## Bigram with Beta computation for positive sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b453f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of postive vocab is : 5039\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 14 10:13:55 2009</td>\n",
       "      <td>&lt;s&gt; awaisnaseer like sedan mango one yesterday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 05 21:02:20 2009</td>\n",
       "      <td>&lt;s&gt; work car work show go bed sooooooooooo tir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 14 22:25:52 2009</td>\n",
       "      <td>&lt;s&gt; drama actually start afternoon try somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 00:42:12 2009</td>\n",
       "      <td>&lt;s&gt; falcon601 www vote col love much &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 17 03:26:30 2009</td>\n",
       "      <td>&lt;s&gt; mrstessyman ever good day love knitpicks &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "1      1  Thu May 14 10:13:55 2009   \n",
       "2      1  Fri Jun 05 21:02:20 2009   \n",
       "3      1  Sun Jun 14 22:25:52 2009   \n",
       "4      1  Sun May 31 00:42:12 2009   \n",
       "5      1  Sun May 17 03:26:30 2009   \n",
       "\n",
       "                                    preprocessed_txt  \n",
       "1  <s> awaisnaseer like sedan mango one yesterday...  \n",
       "2  <s> work car work show go bed sooooooooooo tir...  \n",
       "3  <s> drama actually start afternoon try somethi...  \n",
       "4          <s> falcon601 www vote col love much </s>  \n",
       "5  <s> mrstessyman ever good day love knitpicks </s>  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unigram counts:  for datasets with only positive labels\n",
    "\n",
    "vocab1 = set()\n",
    "unigram_count1={}\n",
    "\n",
    "\n",
    "for x in processed_data['preprocessed_txt'][processed_data.LABEL == 1].to_list():    \n",
    "    for y in x.split():\n",
    "        vocab1.add(y)\n",
    "        if y in unigram_count1:\n",
    "            unigram_count1[y] += 1\n",
    "        else:\n",
    "            unigram_count1[y] = 1\n",
    "\n",
    "            \n",
    "print(\"length of postive vocab is :\", len(vocab1))\n",
    "vocab1 = list(vocab1)\n",
    "processed_data[processed_data.LABEL == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5812a65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'awaisnaseer'), 1),\n",
       " (('awaisnaseer', 'like'), 1),\n",
       " (('like', 'sedan'), 1),\n",
       " (('sedan', 'mango'), 1),\n",
       " (('mango', 'one'), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count bigram frequencies of only existing bigrams for positive label sentences; rest are trivially 0\n",
    "bigram_count1 = {}      \n",
    "            \n",
    "            \n",
    "for line in processed_data[processed_data.LABEL == 1].preprocessed_txt.to_list():\n",
    "            list_words = line.split()\n",
    "            for k in range(len(list_words)-1):\n",
    "                i = list_words[k]\n",
    "                j = list_words[k+1]\n",
    "                if(i,j) in bigram_count1:\n",
    "                    bigram_count1[(i,j)] += 1\n",
    "                else:\n",
    "                    bigram_count1[(i,j)] = 1                \n",
    "                \n",
    "list(bigram_count1.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16eab718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('eqfacebookgrp', 'eqfacebookgrp'), 0.0001984126984126984),\n",
       " (('eqfacebookgrp', 'computer'), 0.0001984126984126984),\n",
       " (('eqfacebookgrp', 'noone'), 0.0001984126984126984),\n",
       " (('eqfacebookgrp', 'essay'), 0.0001984126984126984),\n",
       " (('eqfacebookgrp', 'ncaa'), 0.0001984126984126984)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate updated bigram probability using laplace transform over entire dataset\n",
    "length = len(vocab1)\n",
    "p_bigrams_lap1={}\n",
    "\n",
    "\n",
    "for i in vocab1:\n",
    "    for j in vocab1:\n",
    "        if (i,j) in bigram_count1:\n",
    "            p_bigrams_lap1[(i,j)] = (bigram_count1[(i,j)]+1) / (unigram_count1[i] + length) \n",
    "        else:\n",
    "            p_bigrams_lap1[(i,j)] = 1/(unigram_count1[i]+length)\n",
    "            \n",
    "list(p_bigrams_lap1.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1289bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p_bigrams_lap1.pickle', 'wb') as handle:\n",
    "    pickle.dump(p_bigrams_lap1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del p_bigrams_lap1\n",
    "\n",
    "with open('p_bigrams_lap1.pickle', 'rb') as handle:\n",
    "    p_bigrams_lap1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e38c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating smoothed bigram prob including beta\n",
    "p_bigrams_beta1 = {}\n",
    "\n",
    "\n",
    "for i in vocab:\n",
    "    for j in vocab:\n",
    "        if (i,j) not in bigram_count and (i,j) not in bigram_count1 and i not in unigram_count1:\n",
    "            p_bigrams_beta1[(i,j)] = ((0 + 1 + 5*0) / (unigram_count[i] + length + 5*0))\n",
    "        elif (i,j) in bigram_count and (i,j) not in bigram_count1 and i not in unigram_count1:\n",
    "            p_bigrams_beta1[(i,j)] = ((bigram_count[(i,j)] + 1 + 5*0) / \n",
    "                                     (unigram_count[i] + length + 5*0))      \n",
    "        elif (i,j) not in bigram_count and (i,j) not in bigram_count1 and i in unigram_count1:\n",
    "            p_bigrams_beta1[(i,j)] = ((0 + 1 + 5*0) / \n",
    "                                     (unigram_count[i] + length + 5*unigram_count1[i]))\n",
    "        elif (i,j) in bigram_count and (i,j) not in bigram_count1 and i in unigram_count1:\n",
    "            p_bigrams_beta1[(i,j)] = ((bigram_count[(i,j)] + 1 + 5*0) / \n",
    "                                     (unigram_count[i] + length + 5*unigram_count1[i]))\n",
    "        elif (i,j) in bigram_count and (i,j) in bigram_count1 and i in unigram_count1:\n",
    "            p_bigrams_beta1[(i,j)] = ((bigram_count[(i,j)] + 1 + 5*bigram_count1[(i,j)]) / \n",
    "                                     (unigram_count[i] + length + 5*unigram_count1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdee916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p_bigrams_beta1.pickle', 'wb') as handle:\n",
    "    pickle.dump(p_bigrams_beta1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "del p_bigrams_beta1\n",
    "\n",
    "# # for i in range(10):\n",
    "# #     print(i)\n",
    "\n",
    "with open('p_bigrams_beta1.pickle', 'rb') as handle:\n",
    "    p_bigrams_beta1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4ab97",
   "metadata": {},
   "source": [
    "## Positive sentences generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4acb499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word(context):#generate most probable next word after 'context'\n",
    "    r=random.random()\n",
    "    map_to_probs = {}\n",
    "    \n",
    "    for token in vocab:\n",
    "        map_to_probs[token] = p_bigrams_beta1[(context, token)] #prob. of occurrence of each word 'token' after 'context'\n",
    "\n",
    "    summ = 0  #summ stores cumulative probabilities of occurrence of a word after a 'context' \n",
    "    for token in (map_to_probs):\n",
    "        summ += map_to_probs[token] \n",
    "        if (summ > r):\n",
    "            return token\n",
    "\n",
    "\n",
    "def generate_text(): #returns 1 generated sentence\n",
    "\n",
    "        minn=7\n",
    "        maxx=20\n",
    "        context_queue = '<s>' #current last word seen/generated; sent as 'context' to next_word() function\n",
    "        result = ['<s>']  #entire sentence generated upto present time \n",
    "        \n",
    "        c = 1\n",
    "        while  c<=maxx :\n",
    "            obj = next_word(context_queue)\n",
    "            if obj == '</s>' and c <= minn:\n",
    "                continue\n",
    "            elif obj == '</s>' and c > minn:\n",
    "                break\n",
    "            else: \n",
    "                context_queue=obj\n",
    "                result.append(obj)\n",
    "                c += 1\n",
    "                            \n",
    "        result.append('</s>')\n",
    "        return ' '.join(result)\n",
    "    \n",
    "\n",
    "#genrate 500 sentences using smoothed probabilities with beta positive\n",
    "sentences_beta1 = []\n",
    "for i in range(500):\n",
    "    sentences_beta1.append(generate_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "349ea0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "scores_beta1 = []\n",
    "mod_scores_beta1 = []\n",
    "labels_beta1 = []\n",
    "\n",
    "\n",
    "def sentiment_scores(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    scores_beta1.append(sentiment_dict['compound'])\n",
    "    mod_scores_beta1.append(abs(sentiment_dict['compound']))\n",
    "    \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0 :\n",
    "        labels_beta1.append(1)\n",
    "    else:\n",
    "        labels_beta1.append(0)\n",
    "        \n",
    "        \n",
    "for s in sentences_beta1:\n",
    "    sentiment_scores(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c10e2",
   "metadata": {},
   "source": [
    "## print 5 positive  sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6bf33fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> sometimes psp 14 kudos therealpickler handyman 1st whip strobelight sprinters wickets mya flint launch emilyybrowningg lisaworld kingdom domingo roxannegregorio doreenatdms </s>\n",
      "\n",
      "<s> know transformers conscious italian natmcb78 chesterfield aurea officials cig muster brightside jajjaja friend elon drew123 cream mrstessyman mga springleaf anoopdoggdesai </s>\n",
      "\n",
      "<s> festivallights ijustmightendit grizzly flight eu myinnersexygirl rotten demivenom ahmed nikkithebee cleftmommy0217 indrairwan jk boyhood êµ msrnbjazz picture lad oxo 6 </s>\n",
      "\n",
      "<s> diversitybgt ruthramirez diversitybgt hometown littlebites bonnaroo shrew fact academia knackered ergo clever uu tomsmithmcse nin morrison sl rt announcements alas </s>\n",
      "\n",
      "<s> oh gallery sport grey district factory yeh american disneys pilot apply ì le cheese stem burn honorary realdeal32 shallow section </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentences_beta1[:5]:\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b30912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences with beta positive</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; sometimes psp 14 kudos therealpickler hand...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; know transformers conscious italian natmcb...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; festivallights ijustmightendit grizzly fli...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; diversitybgt ruthramirez diversitybgt home...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; oh gallery sport grey district factory yeh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sentences with beta positive  labels  vader_scores  \\\n",
       "0  <s> sometimes psp 14 kudos therealpickler hand...       1        0.5106   \n",
       "1  <s> know transformers conscious italian natmcb...       1        0.4939   \n",
       "2  <s> festivallights ijustmightendit grizzly fli...       0       -0.3400   \n",
       "3  <s> diversitybgt ruthramirez diversitybgt home...       1        0.0000   \n",
       "4  <s> oh gallery sport grey district factory yeh...       1        0.3818   \n",
       "\n",
       "   mod_vader_scores  \n",
       "0            0.5106  \n",
       "1            0.4939  \n",
       "2            0.3400  \n",
       "3            0.0000  \n",
       "4            0.3818  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vader score for positive sentences :  0.38994379999999984\n"
     ]
    }
   ],
   "source": [
    "df_beta1 = pd.DataFrame({'sentences with beta positive': sentences_beta1, 'labels': labels_beta1, 'vader_scores': scores_beta1, 'mod_vader_scores': mod_scores_beta1})\n",
    "display(df_beta1.head(5))\n",
    "\n",
    "df_beta1.to_csv('df_beta1')\n",
    "\n",
    "df_beta1 = pd.read_csv('df_beta1')\n",
    "mod_scores_beta1 = df_beta1.mod_vader_scores\n",
    "\n",
    "del p_bigrams_beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59e9a723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vader score for positive sentences :  0.38994379999999984\n"
     ]
    }
   ],
   "source": [
    "avg_vader_score_beta1 = sum(mod_scores_beta1) / len(mod_scores_beta1)\n",
    "print(\"average vader score for positive sentences : \", avg_vader_score_beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367c2db",
   "metadata": {},
   "source": [
    "## Negative sentance generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f25dd693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 14:26:50 2009</td>\n",
       "      <td>&lt;s&gt; get thread scar &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Wed Jun 17 09:18:19 2009</td>\n",
       "      <td>&lt;s&gt; need shake gloomy feel maybe rain &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Jun 22 13:51:56 2009</td>\n",
       "      <td>&lt;s&gt; minecraft ride sarah still afraid ride any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri May 22 00:37:02 2009</td>\n",
       "      <td>&lt;s&gt; sokendrakouture yea alone &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Thu May 21 23:50:48 2009</td>\n",
       "      <td>&lt;s&gt; flyingbolt good without &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LABEL                 DATE_TIME  \\\n",
       "0       0  Fri Jun 05 14:26:50 2009   \n",
       "9       0  Wed Jun 17 09:18:19 2009   \n",
       "10      0  Mon Jun 22 13:51:56 2009   \n",
       "12      0  Fri May 22 00:37:02 2009   \n",
       "18      0  Thu May 21 23:50:48 2009   \n",
       "\n",
       "                                     preprocessed_txt  \n",
       "0                            <s> get thread scar </s>  \n",
       "9          <s> need shake gloomy feel maybe rain </s>  \n",
       "10  <s> minecraft ride sarah still afraid ride any...  \n",
       "12                 <s> sokendrakouture yea alone </s>  \n",
       "18                   <s> flyingbolt good without </s>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = processed_data.loc[processed_data.LABEL == 0]\n",
    "display(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1316d8",
   "metadata": {},
   "source": [
    "## Bigram with beta computation for negative sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f06262b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocabuary in negative sentances :  4217\n"
     ]
    }
   ],
   "source": [
    "# unigram counts for negative sentences \n",
    "\n",
    "v2 = set()\n",
    "unigram_count2 = {}\n",
    "\n",
    "for x in df2['preprocessed_txt'].to_list():\n",
    "    for y in x.split():\n",
    "        v2.add(y)\n",
    "        if y in unigram_count2:\n",
    "            unigram_count2[y]+=1\n",
    "        else:\n",
    "            unigram_count2[y]=1\n",
    "\n",
    "print(\"length of vocabuary in negative sentances : \", len(v2))\n",
    "v2 = list(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27dc66a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('<s>', 'get'), 28), (('get', 'thread'), 1), (('thread', 'scar'), 1), (('scar', '</s>'), 2), (('<s>', 'need'), 9)]\n"
     ]
    }
   ],
   "source": [
    "#count bigram frequencies of only existing bigrams for negative label sentences\n",
    "\n",
    "bigram_count2 = {}\n",
    "            \n",
    "for line in df2.preprocessed_txt.to_list():\n",
    "            list_words = line.split()\n",
    "            for k in range(len(list_words)-1):\n",
    "                i=list_words[k]\n",
    "                j=list_words[k+1]\n",
    "                if(i,j) in bigram_count2:\n",
    "                    bigram_count2[(i,j)]+=1\n",
    "                else:\n",
    "                    bigram_count2[(i,j)]=1                \n",
    "                \n",
    "print(list(bigram_count2.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1f63c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('eqfacebookgrp', 'eqfacebookgrp'), 0.00013605442176870748),\n",
       " (('eqfacebookgrp', 'canal'), 0.00013605442176870748),\n",
       " (('eqfacebookgrp', 'computer'), 0.00013605442176870748),\n",
       " (('eqfacebookgrp', 'noone'), 0.00013605442176870748),\n",
       " (('eqfacebookgrp', 'essay'), 0.00013605442176870748)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating smoothed bigram prob including beta\n",
    "length = len(vocab)\n",
    "p_bigrams_beta2 = {}\n",
    "\n",
    "\n",
    "for i in vocab:\n",
    "    for j in vocab:\n",
    "        if (i,j) not in bigram_count and (i,j) not in bigram_count2 and i not in unigram_count2:\n",
    "            p_bigrams_beta2[(i,j)] = ((0 + 1 + 3*0) / (unigram_count[i] + length + 3*0))\n",
    "        elif (i,j) in bigram_count and (i,j) not in bigram_count2 and i not in unigram_count2:\n",
    "            p_bigrams_beta2[(i,j)] = ((bigram_count[(i,j)] + 1 + 3*0) / \n",
    "                                     (unigram_count[i] + length + 3*0))        \n",
    "        elif (i,j) not in bigram_count and (i,j) not in bigram_count2 and i in unigram_count2:\n",
    "            p_bigrams_beta2[(i,j)] = ((0 + 1 + 3*0) / \n",
    "                                     (unigram_count[i] + length + 3*unigram_count2[i]))\n",
    "        elif (i,j) in bigram_count and (i,j) not in bigram_count2 and i in unigram_count2:\n",
    "            p_bigrams_beta2[(i,j)] = ((bigram_count[(i,j)] + 1 + 3*0) / \n",
    "                                     (unigram_count[i] + length + 3*unigram_count2[i]))\n",
    "        elif (i,j) in bigram_count and (i,j) in bigram_count2 and i in unigram_count2:\n",
    "            p_bigrams_beta2[(i,j)] = ((bigram_count[(i,j)] + 1 + 3*bigram_count2[(i,j)]) / \n",
    "                                     (unigram_count[i] + length + 3*unigram_count2[i]))        \n",
    "\n",
    "\n",
    "list(p_bigrams_beta2.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "578838a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p_bigrams_beta2.pickle', 'wb') as handle:\n",
    "    pickle.dump(p_bigrams_beta2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del p_bigrams_beta2\n",
    "\n",
    "with open('p_bigrams_beta2.pickle', 'rb') as handle:\n",
    "    p_bigrams_beta2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afd94b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def next_word(context):#generate most probable next word after 'context'\n",
    "    r=random.random()\n",
    "    map_to_probs = {}\n",
    "    \n",
    "    for token in vocab:\n",
    "        map_to_probs[token] = p_bigrams_beta2[(context, token)] #prob. of occurrence of each word 'token' after 'context'\n",
    "\n",
    "    summ = 0  #summ stores cumulative probabilities of occurrence of a word after a 'context' \n",
    "    for token in (map_to_probs):\n",
    "        summ += map_to_probs[token] \n",
    "        if (summ > r):\n",
    "            return token\n",
    "\n",
    "\n",
    "def generate_text(): #returns 1 generated sentence\n",
    "\n",
    "        minn=7\n",
    "        maxx=20\n",
    "        context_queue = '<s>' #current last word seen/generated; sent as 'context' to next_word() function\n",
    "        result = ['<s>']  #entire sentence generated upto present time \n",
    "        \n",
    "        c = 1\n",
    "        while  c<=maxx :\n",
    "            obj = next_word(context_queue)\n",
    "            if obj == '</s>' and c <= minn:\n",
    "                continue\n",
    "            elif obj == '</s>' and c > minn:\n",
    "                break\n",
    "            else: \n",
    "                context_queue=obj\n",
    "                result.append(obj)\n",
    "                c += 1\n",
    "                            \n",
    "        result.append('</s>')\n",
    "        return ' '.join(result)\n",
    "    \n",
    "\n",
    "#genrate 500 sentences using smoothed probabilities with beta positive\n",
    "sentences_beta2 = []\n",
    "for i in range(500):\n",
    "    sentences_beta2.append(generate_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f7b2f",
   "metadata": {},
   "source": [
    "## Print 5 negative sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b08b5bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> asiabrands divine ashdonaldson cornell highway ramsay begin hoaaaaaaaaaaaaa bookshelf video midsummers acid pie demerol rain invite disco janjohannesson 5pm umahameed </s>\n",
      "\n",
      "<s> allies0r amazon 28 alexis mouth medication abbr depression water iran staaceeyy single johngreenaway upto tacit hurrrrry nhoustonreed sorta machine two </s>\n",
      "\n",
      "<s> ubertwitter bambino woodland carve 5th orissa545 sweetteach81 nelldamylf backup234 classmates teachers mccormicks technique florida s5 az hexmurda richard serena 2call </s>\n",
      "\n",
      "<s> test deadlines amount philgerb mandatory fear draft hardheaded supp dam dot year paddypower hamilton sherinegamal zombie celeb divatheriva 20 croissant </s>\n",
      "\n",
      "<s> crap march actor mercy tolerance jazzyyyyyy 5000000 mummmyyysss video schooooool kimscriven wine stream abandon keithmelton99 plaintruthiness goodluck harper rebound liverpool </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sentences_beta2[:5]:\n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "050b293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "scores_beta2 = []\n",
    "mod_scores_beta2 = []\n",
    "labels_beta2 = []\n",
    "\n",
    "def sentiment_scores(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    scores_beta2.append(sentiment_dict['compound'])\n",
    "    mod_scores_beta2.append(abs(sentiment_dict['compound']))\n",
    "    \n",
    "    # decide sentiment as positive and negative\n",
    "    if sentiment_dict['compound'] > 0 :\n",
    "        labels_beta2.append(1)\n",
    "    else:\n",
    "        labels_beta2.append(0)\n",
    "        \n",
    "        \n",
    "for s in sentences_beta2:\n",
    "    sentiment_scores(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0949b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences with beta negative</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; asiabrands divine ashdonaldson cornell hig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; allies0r amazon 28 alexis mouth medication...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; ubertwitter bambino woodland carve 5th ori...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; test deadlines amount philgerb mandatory f...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; crap march actor mercy tolerance jazzyyyyy...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sentences with beta negative  labels  vader_scores  \\\n",
       "0  <s> asiabrands divine ashdonaldson cornell hig...       1        0.6369   \n",
       "1  <s> allies0r amazon 28 alexis mouth medication...       0       -0.4588   \n",
       "2  <s> ubertwitter bambino woodland carve 5th ori...       0        0.0000   \n",
       "3  <s> test deadlines amount philgerb mandatory f...       0       -0.4404   \n",
       "4  <s> crap march actor mercy tolerance jazzyyyyy...       0       -0.2023   \n",
       "\n",
       "   mod_vader_scores  \n",
       "0            0.6369  \n",
       "1            0.4588  \n",
       "2            0.0000  \n",
       "3            0.4404  \n",
       "4            0.2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_beta2 = pd.DataFrame({'sentences with beta negative': sentences_beta2, 'labels': labels_beta2, 'vader_scores': scores_beta2, 'mod_vader_scores': mod_scores_beta2})\n",
    "display(df_beta2.head(5))\n",
    "\n",
    "df_beta2.to_csv('df_beta2.csv', index=False)\n",
    "df_beta2 = pd.read_csv('df_beta2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ded1ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vader score for negative sentences : 0.3784063999999999\n"
     ]
    }
   ],
   "source": [
    "mod_scores_beta2 = df_beta2.mod_vader_scores\n",
    "avg_vader_score_beta2 = sum(mod_scores_beta2) / len(mod_scores_beta2)\n",
    "print(\"average vader score for negative sentences :\", avg_vader_score_beta2)\n",
    "\n",
    "del p_bigrams_beta2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe3e79",
   "metadata": {},
   "source": [
    "## Data preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0024e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences with beta</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>&lt;s&gt; davidarchie unfold belcourt dufalbagent bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>&lt;s&gt; free lilyjang another ppl mcmahon shiny be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>&lt;s&gt; slowinagoodway incentive mvc2 nikkithebee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>&lt;s&gt; im plzzzz cautious mandatory wtf pinchmysa...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8807</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>&lt;s&gt; pdxsays lucypope respectful vinsharma mast...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentences with beta  labels  vader_scores  \\\n",
       "480  <s> davidarchie unfold belcourt dufalbagent bi...       1        0.9133   \n",
       "232  <s> free lilyjang another ppl mcmahon shiny be...       1        0.9022   \n",
       "316  <s> slowinagoodway incentive mvc2 nikkithebee ...       1        0.8834   \n",
       "66   <s> im plzzzz cautious mandatory wtf pinchmysa...       0       -0.8807   \n",
       "376  <s> pdxsays lucypope respectful vinsharma mast...       1        0.8750   \n",
       "\n",
       "     mod_vader_scores  \n",
       "480            0.9133  \n",
       "232            0.9022  \n",
       "316            0.8834  \n",
       "66             0.8807  \n",
       "376            0.8750  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(250, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta1 = pd.read_csv('df_beta1')\n",
    "df_beta1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_beta1 = df_beta1.sort_values('mod_vader_scores', ascending=False)\n",
    "df_beta1.rename(columns={'sentences with beta positive': 'sentences with beta'}, inplace=True)\n",
    "display(df_beta1.head())\n",
    "df_beta_pos_250 = df_beta1.iloc[:250, :]\n",
    "df_beta_pos_250.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab1fac40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences with beta</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>&lt;s&gt; sukebeuchujin maryyyyyy shittiest pdxsays ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9274</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>&lt;s&gt; sideways dick wan matchesmalone theater mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9201</td>\n",
       "      <td>0.9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>&lt;s&gt; iamsneezy prepare october die poker jrklov...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9022</td>\n",
       "      <td>0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>&lt;s&gt; trouble isp teachers cloud leosgifted1 che...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8779</td>\n",
       "      <td>0.8779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>&lt;s&gt; lx mpt unite saint ne gamesurge star respe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentences with beta  labels  vader_scores  \\\n",
       "329  <s> sukebeuchujin maryyyyyy shittiest pdxsays ...       0       -0.9274   \n",
       "348  <s> sideways dick wan matchesmalone theater mo...       0       -0.9201   \n",
       "199  <s> iamsneezy prepare october die poker jrklov...       0       -0.9022   \n",
       "385  <s> trouble isp teachers cloud leosgifted1 che...       0       -0.8779   \n",
       "138  <s> lx mpt unite saint ne gamesurge star respe...       1        0.8750   \n",
       "\n",
       "     mod_vader_scores  \n",
       "329            0.9274  \n",
       "348            0.9201  \n",
       "199            0.9022  \n",
       "385            0.8779  \n",
       "138            0.8750  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(250, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta2 = pd.read_csv('df_beta2')\n",
    "df_beta2 = df_beta2.sort_values('mod_vader_scores', ascending=False)\n",
    "df_beta2.rename(columns={'sentences with beta negative': 'sentences with beta'}, inplace=True)\n",
    "display(df_beta2.head())\n",
    "df_beta_neg_250 = df_beta2.iloc[:250, :]\n",
    "df_beta_neg_250.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb6e55",
   "metadata": {},
   "source": [
    "## concate sentances of positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea6facb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences with beta</th>\n",
       "      <th>labels</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>mod_vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>&lt;s&gt; davidarchie unfold belcourt dufalbagent bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>&lt;s&gt; free lilyjang another ppl mcmahon shiny be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>&lt;s&gt; slowinagoodway incentive mvc2 nikkithebee ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>&lt;s&gt; im plzzzz cautious mandatory wtf pinchmysa...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8807</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>&lt;s&gt; pdxsays lucypope respectful vinsharma mast...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentences with beta  labels  vader_scores  \\\n",
       "480  <s> davidarchie unfold belcourt dufalbagent bi...       1        0.9133   \n",
       "232  <s> free lilyjang another ppl mcmahon shiny be...       1        0.9022   \n",
       "316  <s> slowinagoodway incentive mvc2 nikkithebee ...       1        0.8834   \n",
       "66   <s> im plzzzz cautious mandatory wtf pinchmysa...       0       -0.8807   \n",
       "376  <s> pdxsays lucypope respectful vinsharma mast...       1        0.8750   \n",
       "\n",
       "     mod_vader_scores  \n",
       "480            0.9133  \n",
       "232            0.9022  \n",
       "316            0.8834  \n",
       "66             0.8807  \n",
       "376            0.8750  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta = pd.concat([df_beta_pos_250, df_beta_neg_250])\n",
    "df_beta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78279083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee26cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vader score after concatination oof postive and negativee sentences : 0.6119588000000001\n"
     ]
    }
   ],
   "source": [
    "mod_vader_scores = df_beta.mod_vader_scores\n",
    "avg_vader_score_beta = sum(mod_vader_scores) / len(mod_vader_scores)\n",
    "print(\"average vader score after concatination oof postive and negativee sentences :\", avg_vader_score_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb7e2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 14:26:50 2009</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 14 10:13:55 2009</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 05 21:02:20 2009</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 14 22:25:52 2009</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 00:42:12 2009</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "0      0  Fri Jun 05 14:26:50 2009   \n",
       "1      1  Thu May 14 10:13:55 2009   \n",
       "2      1  Fri Jun 05 21:02:20 2009   \n",
       "3      1  Sun Jun 14 22:25:52 2009   \n",
       "4      1  Sun May 31 00:42:12 2009   \n",
       "\n",
       "                                                TEXT  \n",
       "0                  About to get threaded and scared   \n",
       "1  @awaisnaseer I like Shezan Mangooo too!!! I ha...  \n",
       "2  worked on my car after work. showering then go...  \n",
       "3  @Marama Actually we start this afternoon!  I w...  \n",
       "4  @gfalcone601 Aww Gi.don't worry.we'll vote for...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                               TEXT\n",
       "0      0                  About to get threaded and scared \n",
       "1      1  @awaisnaseer I like Shezan Mangooo too!!! I ha...\n",
       "2      1  worked on my car after work. showering then go...\n",
       "3      1  @Marama Actually we start this afternoon!  I w...\n",
       "4      1  @gfalcone601 Aww Gi.don't worry.we'll vote for..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(raw_data.head())\n",
    "raw_data.drop(['DATE_TIME'], axis=1, inplace=True)\n",
    "raw_data.rename(columns={'preprocessed_txt': 'sentences'}, inplace=True)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7127538b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>&lt;s&gt; davidarchie unfold belcourt dufalbagent bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>&lt;s&gt; free lilyjang another ppl mcmahon shiny be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>&lt;s&gt; slowinagoodway incentive mvc2 nikkithebee ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>&lt;s&gt; im plzzzz cautious mandatory wtf pinchmysa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>&lt;s&gt; pdxsays lucypope respectful vinsharma mast...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  LABEL\n",
       "480  <s> davidarchie unfold belcourt dufalbagent bi...      1\n",
       "232  <s> free lilyjang another ppl mcmahon shiny be...      1\n",
       "316  <s> slowinagoodway incentive mvc2 nikkithebee ...      1\n",
       "66   <s> im plzzzz cautious mandatory wtf pinchmysa...      0\n",
       "376  <s> pdxsays lucypope respectful vinsharma mast...      1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta.head()\n",
    "temp = df_beta.iloc[:, :2].copy()\n",
    "temp.rename(columns={'labels': 'LABEL', 'sentences with beta': 'sentences'}, inplace=True)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cb85884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset B shape : (4787, 2)\n",
      "raw dataset shape : (4287, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>sentances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                          sentances\n",
       "0      0                  About to get threaded and scared \n",
       "1      1  @awaisnaseer I like Shezan Mangooo too!!! I ha...\n",
       "2      1  worked on my car after work. showering then go...\n",
       "3      1  @Marama Actually we start this afternoon!  I w...\n",
       "4      1  @gfalcone601 Aww Gi.don't worry.we'll vote for..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_B = raw_data.append(temp)\n",
    "dataset_B.drop(['sentences'], axis=1, inplace=True)\n",
    "dataset_B.rename(columns = {'TEXT': 'sentances'}, inplace=True)\n",
    "print(\"dataset B shape :\", dataset_B.shape)\n",
    "print(\"raw dataset shape :\", raw_data.shape)\n",
    "dataset_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e921f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_B.to_csv('dataset_B.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7d56a",
   "metadata": {},
   "source": [
    "## Perplexity evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a98d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def perpleixty_positive(sentence):\n",
    "    words = sentence.split()\n",
    "    n = len(words)\n",
    "    result = 0\n",
    "    \n",
    "    for k in range(n-1):\n",
    "        if k == 0:\n",
    "            result += math.log(unigram_count1[words[k]] / len(vocab))\n",
    "        else:\n",
    "            w1 = words[k]\n",
    "            w2 = words[k+1]\n",
    "            result += math.log(p_bigrams_beta1[(w1, w2)])\n",
    "\n",
    "    result = result * (-1 / n)\n",
    "    result = math.exp(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def perpleixty_negative(sentence):\n",
    "    words = sentence.split()\n",
    "    n = len(words)\n",
    "    result = 0\n",
    "    \n",
    "    for k in range(n-1):\n",
    "        if k == 0:\n",
    "            result += math.log(unigram_count2[words[k]] / len(vocab))\n",
    "        else:\n",
    "            w1 = words[k]\n",
    "            w2 = words[k+1]\n",
    "            result += math.log(p_bigrams_beta2[(w1, w2)])\n",
    "\n",
    "    result = result * (-1 / n)\n",
    "    result = math.exp(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3720bcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postive perplexity score is : 3382.3087853833845\n"
     ]
    }
   ],
   "source": [
    "with open('p_bigrams_beta1.pickle', 'rb') as handle1:\n",
    "    p_bigrams_beta1 = pickle.load(handle1)\n",
    "    \n",
    "df_beta1 = df_beta1.sort_values('mod_vader_scores', ascending=False)\n",
    "postive_perplexity_score  = df_beta1['sentences with beta'][:250].apply(perpleixty_positive).mean()\n",
    "print(\"postive perplexity score is :\", postive_perplexity_score)\n",
    "\n",
    "del p_bigrams_beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "770cd860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative perplexity score is : 3402.3628079430305\n"
     ]
    }
   ],
   "source": [
    "with open('p_bigrams_beta2.pickle', 'rb') as handle2:\n",
    "    p_bigrams_beta2 = pickle.load(handle2)\n",
    "    \n",
    "df_beta2 = df_beta2.sort_values('mod_vader_scores', ascending=False)\n",
    "negative_perplexity_score  = df_beta2['sentences with beta'][:250].apply(perpleixty_negative).mean()\n",
    "print(\"negative perplexity score is :\", negative_perplexity_score)\n",
    "\n",
    "del p_bigrams_beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38888c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average perplexity score of 500 generated sentences :  3391.67\n"
     ]
    }
   ],
   "source": [
    "ans = round((postive_perplexity_score + negative_perplexity_score) / 2, 2)\n",
    "print(\"average perplexity score of 500 generated sentences : \", ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9521dd8",
   "metadata": {},
   "source": [
    "## Extrinsic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78f8a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 29 22:24:26 2009</td>\n",
       "      <td>@mileycyrus cheer up miley whats wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 07 01:37:36 2009</td>\n",
       "      <td>Just got back in from The Belcourt. Saw &amp;quot;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 13 23:41:18 2009</td>\n",
       "      <td>http://bit.ly/IQPPD  with video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 16:43:58 2009</td>\n",
       "      <td>@chloebli heyy!  how was your carnavilistic da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 29 10:36:59 2009</td>\n",
       "      <td>@deadlyseagal http://twitpic.com/66zex - Nice ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "0      1  Fri May 29 22:24:26 2009   \n",
       "1      1  Sun Jun 07 01:37:36 2009   \n",
       "2      1  Wed May 13 23:41:18 2009   \n",
       "3      1  Sun May 31 16:43:58 2009   \n",
       "4      1  Fri May 29 10:36:59 2009   \n",
       "\n",
       "                                                TEXT  \n",
       "0           @mileycyrus cheer up miley whats wrong?   \n",
       "1  Just got back in from The Belcourt. Saw &quot;...  \n",
       "2                   http://bit.ly/IQPPD  with video   \n",
       "3  @chloebli heyy!  how was your carnavilistic da...  \n",
       "4  @deadlyseagal http://twitpic.com/66zex - Nice ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(644, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('A2_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7bc30085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING PIPELINE AT A GLANCE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>white_space_removed</th>\n",
       "      <th>tokenized_data</th>\n",
       "      <th>stopword_removed_data</th>\n",
       "      <th>punct_removed_data</th>\n",
       "      <th>url_removed_data</th>\n",
       "      <th>spelling_checked_data</th>\n",
       "      <th>lemmetized_data</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 29 22:24:26 2009</td>\n",
       "      <td>@mileycyrus cheer up miley whats wrong?</td>\n",
       "      <td>@mileycyrus cheer up miley whats wrong?</td>\n",
       "      <td>[@, mileycyrus, cheer, up, miley, whats, wrong...</td>\n",
       "      <td>[@, mileycyrus, cheer, miley, whats, wrong, ?]</td>\n",
       "      <td>[mileycyrus, cheer, miley, whats, wrong]</td>\n",
       "      <td>[mileycyrus, cheer, miley, whats, wrong]</td>\n",
       "      <td>[mileycyrus, cheer, miley, whats, wrong]</td>\n",
       "      <td>[mileycyrus, cheer, miley, whats, wrong]</td>\n",
       "      <td>&lt;s&gt; mileycyrus cheer miley whats wrong &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 07 01:37:36 2009</td>\n",
       "      <td>Just got back in from The Belcourt. Saw &amp;quot;...</td>\n",
       "      <td>Just got back in from The Belcourt. Saw &amp;quot;...</td>\n",
       "      <td>[just, got, back, in, from, the, belcourt, ., ...</td>\n",
       "      <td>[got, back, belcourt, ., saw, &amp;, quot, ;, fift...</td>\n",
       "      <td>[got, back, belcourt, saw, quot, fifth, quot, ...</td>\n",
       "      <td>[got, back, belcourt, saw, quot, fifth, quot, ...</td>\n",
       "      <td>[got, back, belcourt, saw, quot, fifth, quot, ...</td>\n",
       "      <td>[get, back, belcourt, saw, quot, fifth, quot, ...</td>\n",
       "      <td>&lt;s&gt; get back belcourt saw quot fifth quot awes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 13 23:41:18 2009</td>\n",
       "      <td>http://bit.ly/IQPPD  with video</td>\n",
       "      <td>http://bit.ly/IQPPD with video</td>\n",
       "      <td>[http, :, //bit.ly/iqppd, with, video]</td>\n",
       "      <td>[http, :, //bit.ly/iqppd, video]</td>\n",
       "      <td>[http, video]</td>\n",
       "      <td>[http, video]</td>\n",
       "      <td>[http, video]</td>\n",
       "      <td>[http, video]</td>\n",
       "      <td>&lt;s&gt; http video &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 16:43:58 2009</td>\n",
       "      <td>@chloebli heyy!  how was your carnavilistic da...</td>\n",
       "      <td>@chloebli heyy! how was your carnavilistic day...</td>\n",
       "      <td>[@, chloebli, heyy, !, how, was, your, carnavi...</td>\n",
       "      <td>[@, chloebli, heyy, !, carnavilistic, day, ?, ...</td>\n",
       "      <td>[chloebli, heyy, carnavilistic, day, woow, mad...</td>\n",
       "      <td>[chloebli, heyy, carnavilistic, day, woow, mad...</td>\n",
       "      <td>[chloebli, hey, carnavilistic, day, wood, made...</td>\n",
       "      <td>[chloebli, hey, carnavilistic, day, wood, make...</td>\n",
       "      <td>&lt;s&gt; chloebli hey carnavilistic day wood make w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 29 10:36:59 2009</td>\n",
       "      <td>@deadlyseagal http://twitpic.com/66zex - Nice ...</td>\n",
       "      <td>@deadlyseagal http://twitpic.com/66zex - Nice ...</td>\n",
       "      <td>[@, deadlyseagal, http, :, //twitpic.com/66zex...</td>\n",
       "      <td>[@, deadlyseagal, http, :, //twitpic.com/66zex...</td>\n",
       "      <td>[deadlyseagal, http, nice, day]</td>\n",
       "      <td>[deadlyseagal, http, nice, day]</td>\n",
       "      <td>[deadlyseagal, http, nice, day]</td>\n",
       "      <td>[deadlyseagal, http, nice, day]</td>\n",
       "      <td>&lt;s&gt; deadlyseagal http nice day &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                 DATE_TIME  \\\n",
       "0      1  Fri May 29 22:24:26 2009   \n",
       "1      1  Sun Jun 07 01:37:36 2009   \n",
       "2      1  Wed May 13 23:41:18 2009   \n",
       "3      1  Sun May 31 16:43:58 2009   \n",
       "4      1  Fri May 29 10:36:59 2009   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0           @mileycyrus cheer up miley whats wrong?    \n",
       "1  Just got back in from The Belcourt. Saw &quot;...   \n",
       "2                   http://bit.ly/IQPPD  with video    \n",
       "3  @chloebli heyy!  how was your carnavilistic da...   \n",
       "4  @deadlyseagal http://twitpic.com/66zex - Nice ...   \n",
       "\n",
       "                                 white_space_removed  \\\n",
       "0           @mileycyrus cheer up miley whats wrong?    \n",
       "1  Just got back in from The Belcourt. Saw &quot;...   \n",
       "2                    http://bit.ly/IQPPD with video    \n",
       "3  @chloebli heyy! how was your carnavilistic day...   \n",
       "4  @deadlyseagal http://twitpic.com/66zex - Nice ...   \n",
       "\n",
       "                                      tokenized_data  \\\n",
       "0  [@, mileycyrus, cheer, up, miley, whats, wrong...   \n",
       "1  [just, got, back, in, from, the, belcourt, ., ...   \n",
       "2             [http, :, //bit.ly/iqppd, with, video]   \n",
       "3  [@, chloebli, heyy, !, how, was, your, carnavi...   \n",
       "4  [@, deadlyseagal, http, :, //twitpic.com/66zex...   \n",
       "\n",
       "                               stopword_removed_data  \\\n",
       "0     [@, mileycyrus, cheer, miley, whats, wrong, ?]   \n",
       "1  [got, back, belcourt, ., saw, &, quot, ;, fift...   \n",
       "2                   [http, :, //bit.ly/iqppd, video]   \n",
       "3  [@, chloebli, heyy, !, carnavilistic, day, ?, ...   \n",
       "4  [@, deadlyseagal, http, :, //twitpic.com/66zex...   \n",
       "\n",
       "                                  punct_removed_data  \\\n",
       "0           [mileycyrus, cheer, miley, whats, wrong]   \n",
       "1  [got, back, belcourt, saw, quot, fifth, quot, ...   \n",
       "2                                      [http, video]   \n",
       "3  [chloebli, heyy, carnavilistic, day, woow, mad...   \n",
       "4                    [deadlyseagal, http, nice, day]   \n",
       "\n",
       "                                    url_removed_data  \\\n",
       "0           [mileycyrus, cheer, miley, whats, wrong]   \n",
       "1  [got, back, belcourt, saw, quot, fifth, quot, ...   \n",
       "2                                      [http, video]   \n",
       "3  [chloebli, heyy, carnavilistic, day, woow, mad...   \n",
       "4                    [deadlyseagal, http, nice, day]   \n",
       "\n",
       "                               spelling_checked_data  \\\n",
       "0           [mileycyrus, cheer, miley, whats, wrong]   \n",
       "1  [got, back, belcourt, saw, quot, fifth, quot, ...   \n",
       "2                                      [http, video]   \n",
       "3  [chloebli, hey, carnavilistic, day, wood, made...   \n",
       "4                    [deadlyseagal, http, nice, day]   \n",
       "\n",
       "                                     lemmetized_data  \\\n",
       "0           [mileycyrus, cheer, miley, whats, wrong]   \n",
       "1  [get, back, belcourt, saw, quot, fifth, quot, ...   \n",
       "2                                      [http, video]   \n",
       "3  [chloebli, hey, carnavilistic, day, wood, make...   \n",
       "4                    [deadlyseagal, http, nice, day]   \n",
       "\n",
       "                                    preprocessed_txt  \n",
       "0        <s> mileycyrus cheer miley whats wrong </s>  \n",
       "1  <s> get back belcourt saw quot fifth quot awes...  \n",
       "2                                <s> http video </s>  \n",
       "3  <s> chloebli hey carnavilistic day wood make w...  \n",
       "4                <s> deadlyseagal http nice day </s>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(644, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = preprocess(test_data)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3200469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>sentances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt; mileycyrus cheer miley whats wrong &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt; get back belcourt saw quot fifth quot awes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt; http video &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt; chloebli hey carnavilistic day wood make w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt; deadlyseagal http nice day &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                          sentances\n",
       "0      1        <s> mileycyrus cheer miley whats wrong </s>\n",
       "1      1  <s> get back belcourt saw quot fifth quot awes...\n",
       "2      1                                <s> http video </s>\n",
       "3      1  <s> chloebli hey carnavilistic day wood make w...\n",
       "4      1                <s> deadlyseagal http nice day </s>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(644, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data.drop(['DATE_TIME'], axis=1, inplace=True)\n",
    "display(test_data.head())\n",
    "# test_data.rename(columns={'preprocessed_txt': 'sentances'}, axis=1, inplace=True)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9af9a9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                               TEXT\n",
       "0      0                  About to get threaded and scared \n",
       "1      1  @awaisnaseer I like Shezan Mangooo too!!! I ha...\n",
       "2      1  worked on my car after work. showering then go...\n",
       "3      1  @Marama Actually we start this afternoon!  I w...\n",
       "4      1  @gfalcone601 Aww Gi.don't worry.we'll vote for..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17cf53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_B = pd.read_csv('dataset_B.csv')\n",
    "dataset_B = dataset_B.sample(frac=1)\n",
    "dataset_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "31cdbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_and_evaluate(train_sentences, train_labels, test_sentences, test_labels):\n",
    "    '''\n",
    "    parameters:\n",
    "    train_sentences : list of training sentences\n",
    "    train_labels : list of training labels\n",
    "    test_sentences : list of test sentences\n",
    "    test_labels : list of test labels\n",
    "    output:\n",
    "    accuracy : accuracy of the test set\n",
    "    '''\n",
    "    \n",
    "    # Model building\n",
    "    model = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=30, random_state=333))\n",
    "    \n",
    "    # Training the model with the training data\n",
    "    model.fit(train_sentences, train_labels)\n",
    "    \n",
    "    # Predicting the test data categories\n",
    "    predicted_test_labels = model.predict(test_sentences)\n",
    "    return accuracy_score(test_labels, predicted_test_labels)\n",
    "\n",
    "\n",
    "acc_A = train_and_evaluate(raw_data.TEXT.to_list(), raw_data.LABEL.to_list(), \n",
    "                   test_data.TEXT.to_list(), test_data.LABEL.to_list())\n",
    "\n",
    "acc_B = train_and_evaluate(dataset_B.sentances.to_list(), dataset_B.LABEL.to_list(), \n",
    "                   test_data.TEXT.to_list(), test_data.LABEL.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6fbc8804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy on Dataset A is : 0.785714285714285\n",
      "accracy on dataset B is : 0.796583850931677\n"
     ]
    }
   ],
   "source": [
    "print(\"accracy on Dataset A is : \", acc_A)\n",
    "print(\"accracy on dataset B is : \", acc_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425dbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
